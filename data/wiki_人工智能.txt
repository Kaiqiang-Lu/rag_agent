人工智能（英语：artificial intelligence，缩写为AI），指由人造机器所展现的智慧。

详细定义
通常人工智能是指用普通电脑程式来呈现人类智能的技术。该词也指出研究这样的智能系统是否能够实现，以及如何实现。同时，随著医学、神经科学、机器人学及统计学等方面的发展，普遍认为人类的部分职业也逐渐被其取代。
人工智能于一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年对人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定义为模仿人类与人类思维相关的认知功能的机器或计算机，如学习和解决问题。人工智能是计算机科学的一个分支，它感知其环境并采取行动，最大限度地提高其成功机会。此外，人工智能能够从过去的经验中学习，做出合理的决策，并快速回应。因此，人工智能研究人员的科学目标是通过构建具有象征意义的推理或推理的计算机程式来理解智慧。在计算基础设施之外，人工智能的主要基础组成部分是：

学习（包括机器学习、深度学习、强化学习等子领域）
知识表示、推理与决策
问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案
感知（例如计算机视觉）
自然语言处理（NLP）
生成能力：生成模型与生成式人工智能
人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及范围极广。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。
AI的核心问题包括建构能够跟人类相似，甚至超卓的推理、知识、计划、学习、交流、感知、移动 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已经有初步成果，甚至在一些影像辨识、语言分析、棋类游戏等等单方面的能力达到了超越人类的水平，而且人工智慧的通用性代表著，能解决上述的问题的是一样的AI程式，无须重新开发算法就可以直接使用现有的AI完成任务，与人类的处理能力相同，但达到具备思考能力的统合强人工智慧还需要时间研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的演算法等等也在逐步探索当中。

概论
人工智能的定义可以分为两部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。
关于甚么是「智能」，较有争议性。这涉及到其它诸如意识、自我、心灵，包括无意识的精神等等问题。人唯一了解的智能是人本身的智能，这是普遍认同的观点。但是目前，人类对人类自身智能，与对构成人所拥有智能的必要元素的了解都十分有限，因此很难准确定义甚么是「人工」制造的「智能」。因此人工智能的研究往往涉及对人智能本身的研究。其它关于动物或其它人造系统的智能也普遍被认为是人工智能相关的研究课题。
人工智慧目前在电脑领域内，得到了愈加广泛的发挥。并在机器人、经济政治决策、控制系统、仿真系统中得到应用。
人工智能也广泛应用于许多不同领域。机器人经营餐馆和商店并修复城市基础设施。人工智能管理运输系统和自动驾驶车辆。智能平台管理多个城市领域，例如垃圾收集和空气质量监测。事实上，城市人工智能体现在城市空间、基础设施和技术中，将我们的城市变成了无人监督的自治实体。可以方便地实时实现数字化支持的智能响应服务。许多城市现在主动利用大数据和人工智能，通过为我们的基础设施提供更好的能源、计算能力和连接性来提高经济回报。
最近，由于人工智能减少了行政成本和时间，许多政府开始将人工智能用于各种公共服务。例如，移民流程的机器人自动化减少了处理时间并提高了效率。人工智能为地方政府服务带来技术突破。人工智能代理协助城市规划者基于目标导向的蒙特卡罗树搜索进行场景规划。目标推理人工智能代理提供最佳的土地利用解决方案，帮助人类制定民主的城市土地利用规划。人工智能利用在线数据来监控和修改环境威胁政策。在2019 年水危机期间，潜在狄利克雷分配方法确定了Twitter (X) 中讨论最多的主题，这是一种朴素的推文分类方法，对干旱的影响和原因、政府响应和潜在解决方案等主题进行了分类。人工智能工具与司法部门的人类法官相辅相成，提供客观、一致的风险评估。

发展史
对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。
人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。
与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。
20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。
20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。
在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。
20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。
2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。
2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。
2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。
进入2023年，OpenAI推出了GPT-4，其多模态能力和推理性能显著提升，能处理文本和图像输入，并在复杂问题解决方面展现出更强大的能力。隔年(2024年)，OpenAI进一步发布GPT-4o，这款模型能够处理文本、图像等多种数据类型，并以更自然的对话能力获得广泛应用。
截至2024年，AI技术的应用范围进一步扩大。例如，Anthropic的Claude模型因其安全性和可解释性受到关注，被广泛用于企业应用。与此同时，xAI于2023年推出Grok，旨在加速人类科学发现，特别是在太空探索和物理学领域。根据市场研究，至2024年，全球AI市场规模已达到约1640亿美元，并预计以年复合增长率（CAGR）36.6%持续增长。
2025年，中小型AI模型开始崛起，这些模型以更低的计算需求提供高效性能，受到广泛关注。DeepSeek于2024年12月24日推出了DeepSeek V3，这是一款通用大型语言模型（LLM），并于2025年1月发布DeepSeek R1，专注于复杂逻辑任务的推理模型，两者均提供开源权重和训练方法。DeepSeek R1拥有6710亿(610B)个参数，被认为在推理能力上与OpenAI的o1模型相当，并因其高效的训练方法引发了全球AI竞争的热潮。2025年3月6日，Alibaba Group发布了QwQ-32B，一款320亿(32B)参数的开源推理模型，据称其性能可媲美DeepSeek R1，并在数学、编码和一般问题解决等基准测试中超越OpenAI的o1-mini，且计算需求显著降低。QwQ-32B的发布使阿里巴巴香港上市股票在2025年3月6日上涨超过8%，反映市场对中小型高效模型的看好。

研究课题
目前人工智慧的研究方向已经被分成几个子领域，研究人员希望一个人工智慧系统应该具有某些特定能力，以下将这些能力列出并说明。

演绎、推理和解决问题
早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。
对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。
人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。

知识表示法
知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太阳，除了该如何判断的这件问题，在这个前提之下，应该也能判断出阴天与晴天的差异。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。

规划
智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。
在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。

机器学习
机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。
机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。

自然语言处理
自然语言处理探讨如何处理及运用自然语言，自然语言认知则是指让电脑「懂」人类的语言。自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。

运动和控制
机器感知
机器感知是指能够使用感测器所输入的资料（如照相机、麦克风、声纳以及其他的特殊感测器）然后推断世界的状态。电脑视觉能够分析影像输入。另外还有语音识别、人脸辨识和物体辨识。

社交
情感和社交技能对于一个智能agent是很重要的。首先，通过了解他们的动机和情感状态，代理人能够预测别人的行动（这涉及要素 博弈论、决策理论以及能够塑造人的情感和情绪感知能力检测）。此外，为了良好的人机互动，智慧代理人也需要表现出情绪来。至少它必须出现礼貌地和人类打交道。至少，它本身应该有正常的情绪。

创造力
一个人工智慧的子领域，代表了理论（从哲学和心理学的角度）和实际（通过特定的实现产生的系统的输出是可以考虑的创意，或系统识别和评估创造力）所定义的创造力。相关领域的研究包括了人工直觉和人工想像。

研究方法
目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。
其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？
智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？约翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。

控制论与大脑模拟
20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的乌龟（turtle）和约翰霍普金斯野兽。
这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。

符号处理
当20世纪50年代，数位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工学院，而各自有独立的研究风格。约翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。

认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。
基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。
“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩尔·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。
基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。

子符号方法
1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。

自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。
计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。

统计学方法
1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·诺米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。

集成方法
智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。
代理架构和认知架构：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系统，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。

基本应用
人工智慧基本的应用（Fundamental Applications）可分为四大部分：

感知能力（Perception）
指的是人类透过感官所收到环境的刺激，察觉讯息的能力，简单的说就是人类五官的看、听、说、读、写等能力，学习人类的感知能力是AI目前主要的焦点之一，包括：

「看」：电脑视觉（Computer Vision）、图像辨识（Image Recognition）、人脸辨识（Face Recognition）、物件侦测（Object Detection）。
「听」：语音辨识（Sound Recognition）。
「说」：语音生成（Sound Generation）、文本转换语音（Text-to-Speech）。
「读」：自然语言处理（Natural Language Processing，NLP）、语音转换文本（Speech-to-Text）。
「写」：机器翻译（Machine Translation）、文本生成（Text Generation）

认知能力（Cognition）
指的是人类透过学习、判断、分析等等心理活动来了解讯息、获取知识的过程与能力，对人类认知的模仿与学习也是目前AI第二个焦点领域，主要包括：

分析辨识能力：例如医学图像分析、产品推荐、垃圾邮件辨识、法律案件分析、犯罪侦测、信用风险分析、消费行为分析等。
预测能力：例如AI执行的预防性维修（Predictive Maintenance）、智慧天然灾害预测与防治。
判断能力：例如AI下围棋、自动驾驶车、健保诈欺判断、癌症判断等。
学习能力：例如机器学习、深度学习、增强式学习等等各种学习方法。

创造力（Creativity）
指的是人类产生新思想，新发现，新方法，新理论，新设计，创造新事物的能力，它是结合知识、智力、能力、个性及潜意识等各种因素优化而成，这个领域目前人类仍遥遥领先AI，但AI也试著急起直追，主要领域包括：AI作曲、AI作诗、AI小说、AI绘画、AI设计等。

智慧（Wisdom）
指的是人类深刻了解人、事、物的真相，能探求真实真理、明辨是非，指导人类可以过著有意义生活的一种能力，这个领域牵涉人类自我意识、自我认知与价值观，是目前AI尚未触及的一部分，也是人类最难以模仿的一个领域。

实际应用
机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、无人载具等。

应用领域
智能控制
机器人学
自动化技术
语言和图像理解
遗传编程
法学资讯系统
下棋
医学领域

人工智能伦理
伦理管理
史蒂芬·霍金、比尔盖兹、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都对于人工智慧技术的未来公开表示忧心，人工智慧若在许多方面超越人类智慧水平的智能、不断更新、自我提升，进而取得控制管理权，人类是否有足够的能力及时停止人工智慧领域的「军备竞赛」，能否保有最高掌控权，现有事实是：机器常失控导致人员伤亡，这样的情况是否会更加扩大规模出现，历史显然无法给出可靠的乐观答案。特斯拉电动车马斯克（Elon Musk）在麻省理工学院（MIT）航空航天部门百年纪念研讨会上称人工智能是「召唤恶魔」行为，英国发明家Clive Sinclair认为一旦开始制造抵抗人类和超越人类的智能机器，人类可能很难生存，盖兹同意马斯克和其它人所言，且不知道为何有些人不担忧这个问题。
Google DeepMind的人工智慧（AI）系统在2016年「AlphaGo」对战南韩棋王李世乭获胜，开发商表示在内部设立伦理委员会，针对人工智慧的应用制定政策，防范人工智慧沦为犯罪开发者。
科技进步，人工智慧科技产生「自主武器」军备竞赛已悄悄展开，英国、以色列与挪威，都已部署自主飞弹与无人操控的无人机，具「射后不理」（fire-and-forget）能力的飞弹，多枚飞弹还可互相沟通，分享找到攻击目标。这些武器还未被大量投入，但很快就会出现在战场上，且并非使用人类所设计的程序，而是完全利用机器自行决策。 霍金等人在英国独立报发表文章警告未来人工智慧可能会比人类金融市场、科学家、人类领袖更能操纵人心、甚至研发出人们无法理解的武器。专家恐发展到无法控制的局面，援引联合国禁止研发某些特定武器的「特定常规武器公约」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授认为这是一种欺骗，因为机器无区别战敌和平民的技术。

经济冲击
CNN财经网数字媒体未来学家Amy Webb、美国在线等纷纷预测一些即将被机器人取代的职业，日本野村综合研究所也与英国牛津大学的研究学者共同调查指出，10至20年后，日本有49%的职业（235种职业）可能会被机械和人工智慧取代而消失，直接影响约达2500万人，例如：超市店员、一般事务员、计程车司机、收费站运营商和收银员、市场营销人员、客服人员、制造业工人、金融中间人和分析师、新闻记者、电话公司职员、麻醉师、士兵和保安、律师、医生、软体开发者和操盘手、股票交易员等等高薪酬的脑力职业将最先受到冲击。
2017年6月份马云在美国底特律举行「链结世界」（Gateway 17）产业大会，会上提出人工智慧可能导致第三次世界大战，因为前两次产业革命都导致两次大战，战争原因并非这些创新发明本身，而是发明对社会上许多人的生活方式冲击处理不当，新科技在社会上产生新工作也取代旧工作，产生了新的输家和赢家，若是输家的人数太多将造成一股社会不稳的能量而这股能量被有心人利用可能导致各种事件。他认为各国应该强制订定规定AI机器只能用于人类不能做的工作，避免短时间大量人类被取代的失业大潮，但马云没有提出这种世界性规定将如何实现并确保遵守的细节方案。
数据科学和人工智能被哈佛商业评论称为《二十一世纪最Sexy的职业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司于2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。

AI对人类的威胁
此议题目前分成两个学派：

悲观学派
此学派的代表是天文物理学家史蒂芬·霍金，以及特斯拉执行长伊隆·马斯克。霍金认为AI对人类将来有很大的威胁，主要有以下理由：

AI会遵循科技发展的加速度理论。
AI可能会有自我改造创新的能力。
AI进步的速度远远超过人类。
人类会有被灭绝的危机。

乐观学派
主要是Google、Facebook等AI的主要技术发展者，他们对AI持乐观看法的理由：

人类只要关掉电源就能除掉AI机器人。
任何的科技都会有瓶颈，摩尔定律到目前也遇到相当的瓶颈，AI科技也不会无限成长，依然存在许多难以克服的瓶颈。
依目前的研究方向，电脑无法突变、苏醒、产生自我意志，AI也不可能具有创意与智慧、同情心与审美等这方面的能力。

AI与管理
AI逐渐普及后，将会在企业管理中扮演很重要的角色，而人类的管理者应如何适度的调整自己的工作职能，有以下几点建议：

放弃行政工作；
退守分析预测的领域而强化自己的综合判断力；
把AI当作同事，形成协同合作的团队；
多琢磨在创造力以及各种流程架构设计师角色；
强化自己人际网路、沟通协调、谈判上的能力；
培养自身领导能力，能有效地带领一个士气高、团结及凝结力高的工作伙伴。

滥用
2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。

学科范畴
人工智能是一门边缘学科，属于自然科学和社会科学的交叉。

涉及学科
认知科学
数学及统计学
物理学
逻辑学
控制论及决定论
社会学
犯罪学及智慧犯罪学

研究范畴
哲学
强人工智能和弱人工智能
人工智能的一个比较流行的定义，也是该领域较早的定义，是由当时麻省理工学院的约翰·麦卡锡于1956年的达特矛斯会议上提出的：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样。但是这个定义似乎忽略了强人工智能的可能性（见下）。另一个定义指人工智能是人造机器所表现出来的智能。总体来讲，目前对人工智能的定义大多可划分为四类，即机器「像人一样思考」、「像人一样行动」、「理性地思考」和「理性地行动」。这里「行动」应广义地理解为采取行动，或制定行动的决策，而不是肢体动作。

强人工智能
强人工智能观点认为「有可能」制造出「真正」能推理和解决问题的智能机器，并且，这样的机器将被认为是具有知觉、有自我意识的。强人工智能可以有两类：

人类的人工智能，即机器的思考和推理就像人的思维一样。
非人类的人工智能，即机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式。

弱人工智能
弱人工智能观点认为「不可能」制造出能「真正」地推理和解决问题的智能机器，这些机器只不过「看起来」像是智能的，但是并不真正拥有智能，也不会有自主意识。
弱人工智能是对比强人工智能才出现的，因为人工智能的研究一度处于停滞不前的状态下，直到类神经网路有了强大的运算能力加以模拟后，才开始改变并大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解强人工智能和弱人工智能的内容与差别，对定义争论不休。
就当下的人工智能研究领域来看，研究者已大量造出「看起来」像是智能的机器，取得相当丰硕的理论上和实质上的成果，如2009年康乃尔大学教授Hod Lipson 和其博士研究生Michael Schmidt 研发出的 Eureqa电脑程式，只要给予一些资料，这电脑程式自己只用几十个小时计算就推论出牛顿花费多年研究才发现的牛顿力学公式，等于只用几十个小时就自己重新发现牛顿力学公式，这电脑程式也能用来研究很多其他领域的科学问题上。这些所谓的弱人工智慧在神经网路发展下已经有巨大进步，但对于要如何整合成强人工智慧，现在还没有明确定论。

对强人工智能的哲学争论
主条目：人工智能哲学、图灵测试、物理符号系统、皇帝新脑、德雷福斯对人工智能的看法、AI效应
「强人工智能」一词最初是约翰·瑟尔针对电脑和其它资讯处理机器创造的，其定义为：
「强人工智能观点认为计算机不仅是用来研究人的思维的一种工具；相反，只要运行适当的程序，计算机本身就是有思维的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）
关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。他举了个中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有自我思维和自由意识。
也有哲学家持不同的观点。丹尼尔·丹尼特在其著作《意识的解释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：「人可以有智能，而普通机器就不能」呢？他认为像上述的数据转换机器是有可能有思维和意识的。
有的哲学家认为如果弱人工智能是可实现的，那么强人工智能也是可实现的。比如西蒙·布莱克本（Simon Blackburn）在其哲学入门教材Think里说道，一个人的看起来是「智能」的行动并不能真正说明这个人就真的是智能的。我永远不可能知道另一个人是否真的像我一样是智能的，还是说她／他仅仅是「看起来」是智能的。基于这个论点，既然弱人工智能认为可以令机器「看起来」像是智能的，那就不能完全否定这机器是真的有智能的。布莱克本认为这是一个主观认定的问题。
需要指出的是，弱人工智能并非和强人工智能完全对立，也就是说，即使强人工智能是可能的，弱人工智能仍然是有意义的。至少，今日的计算机能做的事，像算术运算等，在一百多年前是被认为很需要智能的。并且，即使强人工智能被证明为可能的，也不代表强人工智能必定能被研制出来。

挑战与风险
幻觉 (人工智能)——由AI做出的非事实声称
可解释人工智能
人工智能安全及人工智能伦理
人工智能法案——欧盟法律
artificial intelligence in the labour market
通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说

参看
参考文献
引用
来源
注解
扩展阅读
外部连结

What Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.
开放目录项目中的“AI”
AITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.
Artificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）
机器人智能机器人智能
Loebner Prize website（页面存档备份，存于互联网档案馆）
Game AI—计算机游戏开发者的AI资源
Kurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—关于人工智能艺术的网站，里面有著名的人工智能绘画程序AARON
中华民国人工智慧学会 （页面存档备份，存于互联网档案馆）—以促进中华民国人工智慧及相关领域之研究、发展、应用与交流为宗旨的民间组织。