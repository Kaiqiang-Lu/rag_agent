人工智能（英語：artificial intelligence，缩写为AI），指由人造機器所展現的智慧。


== 详细定义 ==
通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。
人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：

学习（包括机器学习、深度学习、强化学习等子领域）
知识表示、推理与决策
问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案
感知（例如计算机视觉）
自然语言处理（NLP）
生成能力：生成模型与生成式人工智能
人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。
AI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。


== 概論 ==

人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。
關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。
人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。
人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。
最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。


== 發展史 ==

对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。
人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。
与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。
20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。
20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。
在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。
20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。
2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。
2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。
2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。
進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。
截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。
2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。


== 研究課題 ==
目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。


=== 演绎、推理和解决问题 ===
早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。
对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。
人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。


=== 知識表示法 ===

知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。


=== 规划 ===
智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。
在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。


=== 機器學習 ===

机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。
机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。


=== 自然語言處理 ===

自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。


=== 運動和控制 ===


=== 機器感知 ===

機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。


=== 社交 ===

情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。


=== 創造力 ===
一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。


== 研究方法 ==
目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。
其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？
智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。


=== 控制论与大脑模拟 ===

20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。
这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。


=== 符号处理 ===

当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。

认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。
基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。
“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。
基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。


=== 子符号方法 ===
1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。

自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。
计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。


=== 统计学方法 ===
1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。


=== 集成方法 ===
智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。
代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。


== 基本應用 ==

人工智慧基本的應用（Fundamental Applications）可分為四大部分：


=== 感知能力（Perception） ===
指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：

「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。
「聽」：語音辨識（Sound Recognition）。
「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。
「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。
「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）


=== 認知能力（Cognition） ===
指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：

分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。
預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。
判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。
學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。


=== 創造力（Creativity） ===
指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。


=== 智慧（Wisdom） ===
指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。


== 實際應用 ==

机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。


=== 應用領域 ===
智能控制
機器人學
自動化技術
語言和圖像理解
遺傳編程
法學資訊系統
下棋
醫學領域


== 人工智能倫理 ==


=== 倫理管理 ===
史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。
Google DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。
科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。


=== 經濟衝擊 ===
CNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。
2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。
数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。


=== AI對人類的威脅 ===
此議題目前分成兩個學派：


==== 悲觀學派 ====
此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：

AI會遵循科技發展的加速度理論。
AI可能會有自我改造創新的能力。
AI進步的速度遠遠超過人類。
人類會有被滅絕的危機。


==== 樂觀學派 ====
主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：

人類只要關掉電源就能除掉AI機器人。
任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。
依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。


=== AI與管理 ===
AI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：

放棄行政工作；
退守分析預測的領域而強化自己的綜合判斷力；
把AI當作同事，形成協同合作的團隊；
多琢磨在創造力以及各種流程架構設計師角色；
強化自己人際網路、溝通協調、談判上的能力；
培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。


=== 滥用 ===

2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。


== 學科範疇 ==
人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。


=== 涉及学科 ===
认知科学
数学及统计学
物理学
逻辑学
控制论及決定論
社会学
犯罪學及智慧犯罪学


=== 研究範疇 ===


== 哲學 ==


=== 強人工智能和弱人工智能 ===
人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。


==== 強人工智能 ====

強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：

人類的人工智能，即機器的思考和推理就像人的思維一樣。
非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。


==== 弱人工智能 ====

弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。
弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。
就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。


==== 對強人工智能的哲學爭論 ====
主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應
「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：
「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）
關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。
也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。
有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。
需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。


== 挑战与风险 ==
幻觉 (人工智能)——由AI做出的非事實聲稱
可解释人工智能
人工智能安全及人工智能伦理
人工智能法案——歐盟法律
artificial intelligence in the labour market
通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说


== 參看 ==


== 参考文献 ==


=== 引用 ===


=== 来源 ===


=== 注解 ===


== 扩展阅读 ==


== 外部連結 ==

What Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.
开放目录项目中的“AI”
AITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.
Artificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）
机器人智能机器人智能
Loebner Prize website（页面存档备份，存于互联网档案馆）
Game AI—計算機遊戲開發者的AI資源
Kurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON
中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。